{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import heapq as hq\n",
    "import pandas as pd\n",
    "\n",
    "# The following function is a useful helper.\n",
    "\n",
    "def second_argmax(x):\n",
    "    ### x: numeric list (or array) of nonzero length\n",
    "    ### Returns: indices of second highest and maximum elements, \n",
    "    ### where index of second highest is -1 if array has length 1.\n",
    "    second_val = -np.inf\n",
    "    second_argmax = -1\n",
    "    max_val = x[0]\n",
    "    argmax = 0\n",
    "    for i in range(1,len(x)):\n",
    "        if (x[i] > max_val):\n",
    "            second_argmax = argmax\n",
    "            second_val = max_val\n",
    "            argmax = i \n",
    "            max_val = x[i]\n",
    "        elif (x[i] > second_val):\n",
    "            second_argmax = i\n",
    "            second_val = x[i]\n",
    "    return second_argmax, argmax\n",
    "\n",
    "def second_argmin(x):\n",
    "    ### x: numeric numpy array of nonzero length\n",
    "    return second_argmax(- x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huntington_hill(populations_array,num_seats):\n",
    "    ### populations is a numpy array of populations\n",
    "    ### num_seats is the desired number of seats to assign\n",
    "    num_states = len(populations_array)\n",
    "    if (num_states > num_seats):\n",
    "        print(\"More states than seats!\")\n",
    "        return None\n",
    "    representatives = np.ones(num_states)\n",
    "    priorities = populations_array / math.sqrt(2)\n",
    "    last_state = None\n",
    "    last_priority = None\n",
    "    second_last_state = None\n",
    "    second_last_state_priority = None\n",
    "    for j in range(num_states,num_seats):\n",
    "        highest = np.argmax(priorities) # index of state with highest priority. It will receive this seat\n",
    "        representatives[highest] +=  1    \n",
    "        # Update this state's priority\n",
    "        priorities[highest] = populations_array[highest]/math.sqrt(\n",
    "            representatives[highest] * (representatives[highest]+1))\n",
    "    # After the for loop,\n",
    "    # representatives contains the number of reps assigned to each state.\n",
    "    # \"priorities\" is an array of the priority of each state fo the next (unassigned) seat. \n",
    "    # invariant: priorities = populations_array / np.sqrt(representatives * (representatives + 1))\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    # Computing the distance to instability. \n",
    "    ############\n",
    "    # CLAIM (no proof): the minimal change consists of \n",
    "    # either adding or removing people to/from a single state. \n",
    "    ############\n",
    "\n",
    "    # We will need the highest and second-highest of the current priorities\n",
    "    second_high, high = second_argmax(priorities)\n",
    "    \n",
    "    # We also need the lowest and second-lowest of the priorities that each state had \n",
    "    # when it was last assigned a seat\n",
    "\n",
    "    prev_norm_factors = np.sqrt(representatives*(representatives - 1)) \n",
    "    #prev_priorities = populations_array / prev_norm_factors\n",
    "    prev_priorities = np.zeros(num_states)\n",
    "    for i in range(num_states):\n",
    "        if (representatives[i] == 1):\n",
    "            prev_priorities[i] = np.inf\n",
    "        else: # normalization factor is not 0\n",
    "            prev_priorities[i] = populations_array[i] / prev_norm_factors[i]\n",
    "\n",
    "    second_low, low = second_argmin (prev_priorities)\n",
    "        \n",
    "    ############\n",
    "    # Step 1: Compute the minimal population addition which would gain some state a new seat.\n",
    "    # For all but one state, this is the addition of population needed to raise their \n",
    "    # priority over min(prev_priorities)\n",
    "    # Let's call this its \"normalized deficiency\"\n",
    "    normalization_factors = np.sqrt(representatives*(representatives + 1))\n",
    "    normalized_defs = (prev_priorities[low] - priorities) * normalization_factors\n",
    "    # Need to fix computation of normalized gap for last state. \n",
    "    # In order for it to gain a seat, it's current priority would have to move above the second \n",
    "    # highest of the priorities. \n",
    "    normalized_defs[low] = (prev_priorities[second_low] - \n",
    "                                       priorities[low]) * normalization_factors[low]\n",
    "\n",
    "    min_addition = np.min(normalized_defs)\n",
    "    min_addition_index = np.argmin(normalized_defs)\n",
    "\n",
    "    ############\n",
    "    # Step 2: Compute the number of people we would have to drop from a state to cost it a seat.\n",
    "    # For all but one state, this is the number of people we need to drop to bring \n",
    "    # the state's priority at the time its last seat was assigned down to the priority \n",
    "    # of the state which would get the next seat, if there were one. \n",
    "    # We'll call this a normalized surplus\n",
    "\n",
    "    # The natural way to write this would be the following:    \n",
    "    #    normalized_surplus = (prev_priorities - priorities[high]) * prev_norm_factors \n",
    "    # but Python doesn't like arrays with np.inf values; instead, we write:\n",
    "    normalized_surplus = populations_array - ( priorities[high] * prev_norm_factors )\n",
    "\n",
    "    # Now we need to fix the surplus for the state which would have gotten the next seat. \n",
    "    normalized_surplus[high] = populations_array[high] - priorities[second_high] * prev_norm_factors[high]\n",
    "\n",
    "    \n",
    "    min_removal = np.min(normalized_surplus)\n",
    "    min_removal_index = np.argmin(normalized_surplus)\n",
    "        \n",
    "    distance_to_instability = min(min_addition, min_removal)    \n",
    "        \n",
    "    stats = dict([\n",
    "        ('representatives', representatives),\n",
    "        ('distance to instability', distance_to_instability),\n",
    "        ('priorities', priorities),\n",
    "        ('previous priorities', prev_priorities),\n",
    "        ('min addition', min_addition),\n",
    "        ('min add inded', min_addition_index),\n",
    "        ('min removal', min_removal),\n",
    "        ('min rem index', min_removal_index),\n",
    "        ('defs', normalized_defs),\n",
    "        ('surps', normalized_surplus)\n",
    "        ])\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with Indian example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "representatives :\n",
      "[ 5.  3. 13.  1.  4. 11.  7. 30. 87. 43.  1.  1.  1.  1.  1.  2.  1. 14.\n",
      " 42. 14. 19. 11. 32. 26.  1.  1. 51. 40. 28.  1.  1. 17. 33.  1.  1.]\n",
      "====\n",
      "distance to instability :\n",
      "60650.0\n",
      "====\n",
      "priorities :\n",
      "[1851977.76885505 1754538.60055381 1805609.13632984  636845.11587395\n",
      " 1898276.14487199 1840398.06866262 1850851.85096836 1852943.68989505\n",
      " 1899435.82287884 1908137.75484105  382439.40971153  776380.61832583\n",
      " 1407167.95040535 1532150.48819364  628315.99387927 1306069.15559686\n",
      " 1639654.76056455 1839406.18388858 1886629.32004193 1859438.85608284\n",
      " 1888039.22079272 1813349.79544139 1857082.03218127 1912454.29486168\n",
      "  111867.12121084  155909.97418382 1881227.0522851  1881871.98686931\n",
      " 1854691.13109657  952945.18158811   42886.02627896 1820250.19666449\n",
      " 1863063.61543597  688965.95671521  251837.49433315]\n",
      "====\n",
      "previous priorities :\n",
      "[2268200.27433646 2481292.28461031 1950280.76920498              inf\n",
      " 2450663.96519734 2016055.07399091 2137179.6287734  1915773.09375199\n",
      " 1921395.34804701 1953041.25735926              inf              inf\n",
      "              inf              inf              inf 2262178.13569235\n",
      "              inf 1975839.19152408 1932096.78987591 1997357.73331169\n",
      " 1990168.08314484 1986425.17522126 1916051.6463026  1987480.80351224\n",
      "              inf              inf 1918482.68982007 1929521.85636555\n",
      " 1922156.35623775              inf              inf 1930666.88627641\n",
      " 1920402.01842191              inf              inf]\n",
      "====\n",
      "min addition :\n",
      "78248.73418905759\n",
      "====\n",
      "min add inded :\n",
      "4\n",
      "====\n",
      "min removal :\n",
      "60650.0\n",
      "====\n",
      "min rem index :\n",
      "30\n",
      "====\n",
      "defs :\n",
      "[ 349421.38509425  558532.66830372 1486193.03850924 1808677.29161353\n",
      "   78248.73418906  865993.10722056  485826.0952398  1924534.01388554\n",
      " 1429487.86225208  332115.30127227 2168461.29161353 1611344.29161353\n",
      "  719276.29161353  542524.29161353 1820739.29161353 1493463.5426455\n",
      "  390490.29161353 1106661.661773   1238524.66273     816360.661773\n",
      "  540632.71223815 1176754.10722056 1907233.75283769   87932.51448798\n",
      " 2551108.29161353 2488822.29161353 1779037.28395355 1372890.1917154\n",
      " 1740568.01171699 1361644.29161353 2648662.29161353 1670968.25332044\n",
      " 1765570.83547422 1734967.29161353 2353160.29161353]\n",
      "====\n",
      "surps :\n",
      "[1590944.38565571 1393362.82119468  472452.51312078  900635.\n",
      " 1864412.98829252 1086574.13828062 1456386.61744501   97890.5035469\n",
      "  773388.17982602 1724826.52859722  540851.         1097968.\n",
      " 1990036.         2166788.          888573.          494584.19878794\n",
      " 2318822.          855109.00634509  815104.37680162 1145410.00634509\n",
      " 1437179.8941495   775813.13828062  113302.29428571 2022858.76721188\n",
      "  158204.          220490.          304419.02326348  674114.66596836\n",
      "  266762.58391774 1347668.           60650.          300369.75247661\n",
      "  258270.44573091  974345.          356152.        ]\n"
     ]
    }
   ],
   "source": [
    "example_populations_table = pd.DataFrame(\n",
    "    [[\"JAMMU & KASHMIR\",10143700],[\"HIMACHAL PRADESH\",6077900],[\"PUNJAB\",24358999],\n",
    "    [\"CHANDIGARH\",900635],[\"UTTARANCHAL\",8489349],[\"HARYANA\",21144564],[\"DELHI\",13850507],\n",
    "    [\"RAJASTHAN\",56507188],[\"UTTAR PRADESH\",166197921],[\"BIHAR\",82998509],\n",
    "    [\"SIKKIM\",540851],[\"ARUNACHAL PRADESH\",1097968],[\"NAGALAND\",1990036],\n",
    "    [\"MANIPUR\",2166788],[\"MIZORAM\",888573],[\"TRIPURA\",3199203],\n",
    "    [\"MEGHALAYA\",2318822],[\"ASSAM\",26655528],[\"WEST BENGAL\",80176197],\n",
    "    [\"JHARKHAND\",26945829],[\"ORISSA\",36804660],[\"CHHATTISGARH\",20833803],\n",
    "    [\"MADHYA PRADESH\",60348023],[\"GUJARAT\",50671017],[\"DAMAN & DIU\",158204],\n",
    "    [\"DADRA & NAGAR HAVELI\",220490],[\"MAHARASHTRA\",96878627],[\"ANDHRA PRADESH\",76210007],\n",
    "    [\"KARNATAKA\",52850562],[\"GOA\",1347668],[\"LAKSHADWEEP\",60650],\n",
    "    [\"KERALA\",31841374],[\"TAMIL NADU\",62405679],[\"PONDICHERRY\",974345],\n",
    "    [\"ANDAMAN & NICOBAR ISLANDS\",356152]\n",
    "    ] )\n",
    "\n",
    "example_populations_array = example_populations_table[1].values\n",
    "\n",
    "number_of_seats = 545\n",
    "\n",
    "stats = huntington_hill(example_populations_array, number_of_seats)\n",
    "\n",
    "for x in stats:\n",
    "    print(\"====\")\n",
    "    print(x, \":\")\n",
    "    print(stats[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How likely is noise addition to changed apportioned seats? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huntington_hill_noise(populations_array, num_seats, epsilon, num_reps):\n",
    "    ### populations_array is a numpy array  containing the states' populations\n",
    "    ### num_seats is the desired number of seats to assign\n",
    "    ### epsilon is the parameter used for DP noise addition (Laplace noise)\n",
    "    ### num_reps is the number of attempts that are made\n",
    "    ### Returns a numpy array\n",
    "    ref_stats = huntington_hill(populations_array, num_seats)\n",
    "    ref_reps = ref_stats['representatives']\n",
    "    distance_to_instab = ref_stats['distance to instability']\n",
    "    changed_outputs = 0\n",
    "    total_changes = 0\n",
    "    for i in range(num_reps):\n",
    "        noisy_pops = Laplace_Histogram(populations_array, epsilon)\n",
    "        reps = huntington_hill(noisy_pops, num_seats)['representatives']\n",
    "        if not np.array_equal(reps, ref_reps):\n",
    "            changed_outputs = changed_outputs + 1\n",
    "        total_changes = total_changes + np.linalg.norm(reps - ref_reps, ord = 1)\n",
    "    if (changed_outputs == 0):\n",
    "        avg_change = 0.0\n",
    "    else:\n",
    "        avg_change = total_changes / changed_outputs\n",
    "    return changed_outputs, avg_change, distance_to_instab\n",
    "\n",
    "def Laplace_Histogram(populations_array, epsilon):\n",
    "    num_states = len(populations_array)\n",
    "    return populations_array + np.random.laplace(scale = 1/epsilon, size = (num_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying this with the Indian population data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 trials, there were 18 trials where the apportionment totals differed from the exact totals. Of those, the average number of seats that changed was 2.0. The distance to instability was 60650.0.\n"
     ]
    }
   ],
   "source": [
    "(n, e, d) = huntington_hill_noise(example_populations_array, \n",
    "                      number_of_seats,\n",
    "                      epsilon = 0.00003, \n",
    "                      num_reps = 100)\n",
    "print(\"Out of 100 trials, there were {} trials where the \\\n",
    "apportionment totals differed from the exact totals. \\\n",
    "Of those, the average number of seats that changed \\\n",
    "was {}. The distance to instability was {}.\".format(n, e, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with US historical data\n",
    "\n",
    "First, we load the population data into memory. \n",
    "\n",
    "This data comes from two sources: \n",
    "* 1790 through 1990: https://www.census.gov/population/www/censusdata/pop1790-1990.html\n",
    "* 2000, 2010, and 2017 (estimated): https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population \n",
    "* Note that the 2017 numbers don't actually come from a decennial census. They are just there for fun.\n",
    "\n",
    "The data on the number of seats historically apportioned comes from \n",
    "https://en.wikipedia.org/wiki/United_States_congressional_apportionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_pops = pd.read_csv('historical_populations.csv', header = 0)\n",
    "\n",
    "us_seats = pd.read_csv('historical_seats_apportioned.csv', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete the total US population as well as the District of Columbia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', '2017', '2010', '2000', '1990', '1980', '1970', '1960', '1950',\n",
      "       '1940', '1930', '1920', '1910', '1900', '1890', '1880', '1870', '1860',\n",
      "       '1850', '1840', '1830', '1820', '1810', '1800', '1790',\n",
      "       'Year of first census', 'No significant change since', 'FIPS Code'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>2017</th>\n",
       "      <th>2010</th>\n",
       "      <th>2000</th>\n",
       "      <th>1990</th>\n",
       "      <th>1980</th>\n",
       "      <th>1970</th>\n",
       "      <th>1960</th>\n",
       "      <th>1950</th>\n",
       "      <th>1940</th>\n",
       "      <th>...</th>\n",
       "      <th>1850</th>\n",
       "      <th>1840</th>\n",
       "      <th>1830</th>\n",
       "      <th>1820</th>\n",
       "      <th>1810</th>\n",
       "      <th>1800</th>\n",
       "      <th>1790</th>\n",
       "      <th>Year of first census</th>\n",
       "      <th>No significant change since</th>\n",
       "      <th>FIPS Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4833722</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4447100</td>\n",
       "      <td>4040587</td>\n",
       "      <td>3893888</td>\n",
       "      <td>3444165</td>\n",
       "      <td>3266740</td>\n",
       "      <td>3061743</td>\n",
       "      <td>2832961</td>\n",
       "      <td>...</td>\n",
       "      <td>771623.0</td>\n",
       "      <td>590756.0</td>\n",
       "      <td>309527.0</td>\n",
       "      <td>127901.0</td>\n",
       "      <td>9046.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>1820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>739795</td>\n",
       "      <td>710231</td>\n",
       "      <td>626932</td>\n",
       "      <td>550043</td>\n",
       "      <td>401851</td>\n",
       "      <td>300382</td>\n",
       "      <td>226167</td>\n",
       "      <td>128643</td>\n",
       "      <td>72524</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>1880</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7016270</td>\n",
       "      <td>6392017</td>\n",
       "      <td>5130632</td>\n",
       "      <td>3665228</td>\n",
       "      <td>2718215</td>\n",
       "      <td>1770900</td>\n",
       "      <td>1302161</td>\n",
       "      <td>749587</td>\n",
       "      <td>499261</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1860</td>\n",
       "      <td>1870</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2959373</td>\n",
       "      <td>2915918</td>\n",
       "      <td>2673400</td>\n",
       "      <td>2350725</td>\n",
       "      <td>2286435</td>\n",
       "      <td>1923295</td>\n",
       "      <td>1786272</td>\n",
       "      <td>1909511</td>\n",
       "      <td>1949387</td>\n",
       "      <td>...</td>\n",
       "      <td>209897.0</td>\n",
       "      <td>97574.0</td>\n",
       "      <td>30388.0</td>\n",
       "      <td>14273.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1810</td>\n",
       "      <td>1830</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>39536653</td>\n",
       "      <td>37253956</td>\n",
       "      <td>33871648</td>\n",
       "      <td>29760021</td>\n",
       "      <td>23667902</td>\n",
       "      <td>19953134</td>\n",
       "      <td>15717204</td>\n",
       "      <td>10586223</td>\n",
       "      <td>6907387</td>\n",
       "      <td>...</td>\n",
       "      <td>92597.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1850</td>\n",
       "      <td>1860</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name      2017      2010      2000      1990      1980      1970  \\\n",
       "1     Alabama   4833722   4779736   4447100   4040587   3893888   3444165   \n",
       "2      Alaska    739795    710231    626932    550043    401851    300382   \n",
       "3     Arizona   7016270   6392017   5130632   3665228   2718215   1770900   \n",
       "4    Arkansas   2959373   2915918   2673400   2350725   2286435   1923295   \n",
       "5  California  39536653  37253956  33871648  29760021  23667902  19953134   \n",
       "\n",
       "       1960      1950     1940    ...          1850      1840      1830  \\\n",
       "1   3266740   3061743  2832961    ...      771623.0  590756.0  309527.0   \n",
       "2    226167    128643    72524    ...           NaN       NaN       NaN   \n",
       "3   1302161    749587   499261    ...           NaN       NaN       NaN   \n",
       "4   1786272   1909511  1949387    ...      209897.0   97574.0   30388.0   \n",
       "5  15717204  10586223  6907387    ...       92597.0       NaN       NaN   \n",
       "\n",
       "       1820    1810    1800  1790  Year of first census  \\\n",
       "1  127901.0  9046.0  1250.0   NaN                  1800   \n",
       "2       NaN     NaN     NaN   NaN                  1880   \n",
       "3       NaN     NaN     NaN   NaN                  1860   \n",
       "4   14273.0  1062.0     NaN   NaN                  1810   \n",
       "5       NaN     NaN     NaN   NaN                  1850   \n",
       "\n",
       "   No significant change since  FIPS Code  \n",
       "1                         1820        1.0  \n",
       "2                         1880        2.0  \n",
       "3                         1870        4.0  \n",
       "4                         1830        5.0  \n",
       "5                         1860        6.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_pops = us_pops.drop([0,9]) \n",
    "\n",
    "print(us_pops.columns)\n",
    "us_pops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to process the number of seats apportioned in each Census year.\n",
    "\n",
    "* According to Wikipeda, \"Congress failed to pass any reapportionment to implement the 1920 United States Census so despite population shift, distribution of seats from 1913 remained in effect until 1933.\" For experiments, we will use the total from 1910. \n",
    "\n",
    "* For experiments with the 2017 estimates, we use the total from 2010.\n",
    "\n",
    "Both of these fictitious numbers happen to be 435. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>1790</th>\n",
       "      <th>1800</th>\n",
       "      <th>1810</th>\n",
       "      <th>1820</th>\n",
       "      <th>1830</th>\n",
       "      <th>1840</th>\n",
       "      <th>1850</th>\n",
       "      <th>1860</th>\n",
       "      <th>1870</th>\n",
       "      <th>...</th>\n",
       "      <th>1910</th>\n",
       "      <th>1930</th>\n",
       "      <th>1940</th>\n",
       "      <th>1950</th>\n",
       "      <th>1960</th>\n",
       "      <th>1970</th>\n",
       "      <th>1980</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of seats apportioned</td>\n",
       "      <td>105</td>\n",
       "      <td>142</td>\n",
       "      <td>182</td>\n",
       "      <td>213</td>\n",
       "      <td>240</td>\n",
       "      <td>223</td>\n",
       "      <td>234</td>\n",
       "      <td>241</td>\n",
       "      <td>292</td>\n",
       "      <td>...</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Year  1790  1800  1810  1820  1830  1840  1850  \\\n",
       "0  Number of seats apportioned   105   142   182   213   240   223   234   \n",
       "\n",
       "   1860  1870  ...   1910  1930  1940  1950  1960  1970  1980  1990  2000  \\\n",
       "0   241   292  ...    435   435   435   435   435   435   435   435   435   \n",
       "\n",
       "   2010  \n",
       "0   435  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_seats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_seats['1920'] = us_seats['1910']\n",
    "us_seats['2017'] = us_seats['2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  1.  9.  4. 53.  7.  5.  1. 27. 14.  2.  2. 18.  9.  4.  4.  6.  6.\n",
      "  2.  8.  9. 14.  8.  4.  8.  1.  3.  4.  2. 12.  3. 27. 13.  1. 16.  5.\n",
      "  5. 18.  2.  7.  1.  9. 36.  4.  1. 11. 10.  3.  8.  1.]\n"
     ]
    }
   ],
   "source": [
    "representatives2010 = huntington_hill(us_pops['2010'].values, num_seats = 435)['representatives']\n",
    "print(representatives2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_years = us_pops.columns.drop(['Name', 'Year of first census',\n",
    "       'No significant change since', 'FIPS Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code repeatedly adds Laplace noise to state populations and checks if the apportionment changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "Now trying epsilon =  1.0\n",
      "Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\n",
      "2017 435   0   0.00 7786.55\n",
      "2010 435   0   0.00 12408.13\n",
      "2000 435   0   0.00 691.25\n",
      "1990 435   0   0.00 835.49\n",
      "1980 435   0   0.00 7421.60\n",
      "1970 435   0   0.00 692.97\n",
      "1960 435   0   0.00 11435.18\n",
      "1950 435   0   0.00 1875.56\n",
      "1940 435   0   0.00 1179.56\n",
      "1930 435   0   0.00 117.07\n",
      "1920 435   0   0.00 3938.67\n",
      "1910 435   0   0.00 5158.55\n",
      "1900 386   0   0.00 4914.92\n",
      "==============\n",
      "Now trying epsilon =  0.1\n",
      "Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\n",
      "2017 435   0   0.00 7786.55\n",
      "2010 435   0   0.00 12408.13\n",
      "2000 435   0   0.00 691.25\n",
      "1990 435   0   0.00 835.49\n",
      "1980 435   0   0.00 7421.60\n",
      "1970 435   0   0.00 692.97\n",
      "1960 435   0   0.00 11435.18\n",
      "1950 435   0   0.00 1875.56\n",
      "1940 435   0   0.00 1179.56\n",
      "1930 435   0   0.00 117.07\n",
      "1920 435   0   0.00 3938.67\n",
      "1910 435   0   0.00 5158.55\n",
      "1900 386   0   0.00 4914.92\n",
      "==============\n",
      "Now trying epsilon =  0.01\n",
      "Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\n",
      "2017 435   0   0.00 7786.55\n",
      "2010 435   0   0.00 12408.13\n",
      "2000 435   0   0.00 691.25\n",
      "1990 435   0   0.00 835.49\n",
      "1980 435   0   0.00 7421.60\n",
      "1970 435   0   0.00 692.97\n",
      "1960 435   0   0.00 11435.18\n",
      "1950 435   0   0.00 1875.56\n",
      "1940 435   0   0.00 1179.56\n",
      "1930 435  30   2.00 117.07\n",
      "1920 435   0   0.00 3938.67\n",
      "1910 435   0   0.00 5158.55\n",
      "1900 386   0   0.00 4914.92\n",
      "==============\n",
      "Now trying epsilon =  0.001\n",
      "Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\n",
      "2017 435   0   0.00 7786.55\n",
      "2010 435   0   0.00 12408.13\n",
      "2000 435  30   2.00 691.25\n",
      "1990 435  28   2.00 835.49\n",
      "1980 435   0   0.00 7421.60\n",
      "1970 435  30   2.00 692.97\n",
      "1960 435   0   0.00 11435.18\n",
      "1950 435   5   2.00 1875.56\n",
      "1940 435  15   2.00 1179.56\n",
      "1930 435  65   2.00 117.07\n",
      "1920 435   0   0.00 3938.67\n",
      "1910 435   0   0.00 5158.55\n",
      "1900 386   0   0.00 4914.92\n",
      "==============\n",
      "Now trying epsilon =  0.0001\n",
      "Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\n",
      "2017 435  53   2.08 7786.55\n",
      "2010 435  43   2.00 12408.13\n",
      "2000 435  67   2.15 691.25\n",
      "1990 435  82   2.80 835.49\n",
      "1980 435  44   2.05 7421.60\n",
      "1970 435  84   2.52 692.97\n",
      "1960 435  49   2.12 11435.18\n",
      "1950 435  82   2.51 1875.56\n",
      "1940 435  65   2.06 1179.56\n",
      "1930 435  95   2.86 117.07\n",
      "1920 435  85   3.11 3938.67\n",
      "1910 435  67   2.33 5158.55\n",
      "1900 386  86   2.81 4914.92\n"
     ]
    }
   ],
   "source": [
    "for epsilon in [1.0, 0.1, 0.01, 0.001, 0.0001]:\n",
    "    print(\"==============\")\n",
    "    print(\"Now trying epsilon = \", epsilon)\n",
    "    print(\"Each row lists: year, number of seats, number of trials (out of 100) that yielded different apportionment, the average number of seats that changed, and the distance to instability for taht year's real numbers.\")\n",
    "    for year in list_of_years[0:13]: \n",
    "        (n,e, d) = huntington_hill_noise(us_pops[year].values, \n",
    "                          num_seats = us_seats[year][0],\n",
    "                          epsilon = epsilon, \n",
    "                          num_reps = 100)\n",
    "        print('{} {} {:3d}   {:.2f} {:.2f}'.format(year, us_seats[year][0], n, e, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to write code to handle years with missing populations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
